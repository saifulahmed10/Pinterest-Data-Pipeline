# Pinterest-Data-Pipeline

This pipeline will extract, transform and load data from an API using batch processing and stream processing, using the following Apache services:
- Apache Spark
- Apache Kafka
- Apache Airflow
- Apache Kinesis

These services will be used in conjunction with AWS, to create VPC which will contain an EC2 instance for its consumer and producer.

# Technologies Used

- ***`Apache Kafka`***    ***`Python`***
- ***`Apache Spark`***    ***`SQL`***
- ***`Apache Airflow`***  ***`Databricks`***
- ***`Apache Kinesis`***

Set up environment on AWS and GitHub 

.pem file extension was created to save the key-pair file locally. Which would allow me to connect to my EC2 instance.

Next I connected to the EC2 instance using the SSH client
